name: multitask_ae_ddpm

load_episode_vae: True
no_train_last: True

ae_model:
  _target_: core.module.modules.transformer_ae.TransformerAE
  d_model: 32
  nhead: 1
  depth: 3
  dim_feedforward: 256
  dropout: 0.1
  patch_size: 2048
  input_noise_factor: 0.001
  latent_noise_factor: 0.1
  condition_num: 0

model:
  _target_: core.module.modules.dit.DiT
  patch_size: 16
  depth: 2
  condition_num: 0
  hidden_size: 64

beta_schedule:
  start: 1e-4
  end: 2e-2
  schedule: linear
  n_timestep: 100

model_mean_type: eps
model_var_type: fixedlarge
loss_type: mse

train:
  split_epoch: 20000
  ae_eval_batch_size: 20
  ddpm_eval_batch_size: 20
  ae_use_condition: false
  optimizer:
    _target_: torch.optim.AdamW
    lr: 3e-4
    weight_decay: 2e-6

  ae_optimizer:
    _target_: torch.optim.AdamW
    lr: 3e-4
    weight_decay: 2e-6

  lr_scheduler:

  trainer:
    _target_: pytorch_lightning.Trainer
    _convert_: all
    max_epochs: 80000
    check_val_every_n_epoch:
    val_check_interval : 5000
    log_every_n_steps: 10
    limit_val_batches: 1
    limit_test_batches: 1
    devices:
      - ${device.id}

    enable_model_summary: false

    callbacks:
    - _target_: pytorch_lightning.callbacks.ModelCheckpoint
      monitor: 'mean_g_acc'
      mode: 'max'
      save_top_k: 1
      save_last: true
      verbose: true
      filename: 'ddpm-{epoch}-{mean_g_acc:.4f}'

    - _target_: pytorch_lightning.callbacks.ModelCheckpoint
      filename: "ae-{epoch}-{mean_ae_acc:.4f}"
      monitor: 'mean_ae_acc'
      mode: 'max'
      save_top_k: 1
      save_last: false
      verbose: true

    logger:
      _target_: pytorch_lightning.loggers.TensorBoardLogger
      save_dir: ${output_dir}/${system.name}/
      name: '.'
      version: '.'